{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "second_algorithm_experiments.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHu3YVRSscVX"
   },
   "source": [
    "### 1. Download and setup all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0hQi3sBvsPZ_"
   },
   "source": [
    "!pip install maxvolpy tntorch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DRISU4YXsiJ6"
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MVtDNPDtsozM"
   },
   "source": [
    "### 2. Experiment function"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "unpjJ8MJsrdi"
   },
   "source": [
    "from tensor_extraction import extract_tensor_with_cross\n",
    "from wfa_extraction import wfa_extraction, create_hankel_matrices, create_hankel_matrices_on_random_sets\n",
    "from spectral_learning import spectral_learning\n",
    "from utils import func_difference_metrics\n",
    "\n",
    "\n",
    "def experiment(func, filename, alphabet_size_list, ranks_list, n_list, max_length, max_iter):\n",
    "    df_result = pd.DataFrame(columns=['alphabet_size',\n",
    "                                      'rank',\n",
    "                                      'n',\n",
    "                                      'n_evaluations',\n",
    "                                      'set_size',\n",
    "                                      'tensor_extraction_time',\n",
    "                                      'val_epss',\n",
    "                                      'cross_wfa_extraction_time',\n",
    "                                      'hankel_creation_time[short]',\n",
    "                                      'spectral_wfa_extraction_time[short]',\n",
    "                                      'hankel_creation_time[random]',\n",
    "                                      'spectral_wfa_extraction_time[random]',\n",
    "                                      'error_max[cross]',\n",
    "                                      'error_avg[cross]',\n",
    "                                      'error_max[short]',\n",
    "                                      'error_avg[short]',\n",
    "                                      'error_max[random]',\n",
    "                                      'error_avg[random]'])\n",
    "\n",
    "    for alphabet_size in alphabet_size_list:\n",
    "        print('Starting experiment with alphabet_size={}'.format(alphabet_size))\n",
    "\n",
    "        F = func\n",
    "        F.alphabet_size = alphabet_size\n",
    "\n",
    "        for rank in ranks_list:\n",
    "            print('Starting experiment with alphabet_size={}, rank={}'.format(alphabet_size, rank))\n",
    "            for n in n_list:\n",
    "                print('Starting experiment with alphabet_size={}, rank={}, n={}'.format(alphabet_size, rank, n))\n",
    "\n",
    "                #tensor extraction\n",
    "                tensor_extraction_time = time.time()\n",
    "                tensor, info = extract_tensor_with_cross(F, n, rank=rank, max_iter=max_iter, return_info=True,\n",
    "                                                         kickrank=rank, rmax=1000)\n",
    "                tensor_extraction_time = time.time() - tensor_extraction_time\n",
    "                print('Tensor was extracted, time={:.5}'.format(tensor_extraction_time))\n",
    "                n_evaluations = info['nsamples']\n",
    "                print('The number of evaluations was {}'.format(n_evaluations))\n",
    "                #automaton extraction from tensor\n",
    "                cross_wfa_extraction_time = time.time()\n",
    "                W_cross = wfa_extraction(tensor, rank=rank)\n",
    "                cross_wfa_extraction_time = time.time() - cross_wfa_extraction_time\n",
    "                print('WFA was extracted from tensor, time={:.5}'.format(cross_wfa_extraction_time))\n",
    "\n",
    "                #spectral learning [short]\n",
    "                set_size = int(np.sqrt((n_evaluations + alphabet_size) // (alphabet_size + 1))) + 1\n",
    "                print('The size of prefixes and suffixes set is {}'.format(set_size))\n",
    "                set_size = max(set_size, rank + 1)\n",
    "                #Hankel matrices creation\n",
    "                hankel_creation_time = time.time()\n",
    "                hPref, hSuf, H = create_hankel_matrices(F, kPref=set_size, kSuf=set_size)\n",
    "                hankel_creation_time = time.time() - hankel_creation_time\n",
    "                print('Hankel matrices has been created, time={:.5}'.format(hankel_creation_time))\n",
    "                #automaton extraction from Hankel matrices\n",
    "                spectral_wfa_extraction_time = time.time()\n",
    "                W_spectral = spectral_learning(hPref, hSuf, H, rank)\n",
    "                spectral_wfa_extraction_time = time.time() - spectral_wfa_extraction_time\n",
    "                print('WFA was extracted from Hankel matrices, time={:.5}'.format(spectral_wfa_extraction_time))\n",
    "\n",
    "                #spectral learning [random]\n",
    "                #Hankel matrices creation\n",
    "                random_hankel_creation_time = time.time()\n",
    "                hPref, hSuf, H = create_hankel_matrices_on_random_sets(F, n, n, set_size, set_size)\n",
    "                random_hankel_creation_time = time.time() - random_hankel_creation_time\n",
    "                print('Hankel matrices has been created, time={:.5}'.format(random_hankel_creation_time))\n",
    "                #automaton extraction from Hankel matrices\n",
    "                random_spectral_wfa_extraction_time = time.time()\n",
    "                W_random = spectral_learning(hPref, hSuf, H, rank)\n",
    "                random_spectral_wfa_extraction_time = time.time() - random_spectral_wfa_extraction_time\n",
    "                print('WFA was extracted from Hankel matrices, time={:.5}'.format(\n",
    "                    random_spectral_wfa_extraction_time))\n",
    "\n",
    "                # difference evaluation\n",
    "                cross_error_max, cross_error_avg = func_difference_metrics(F, W_cross, max_length=max_length)\n",
    "                print('errors has been evaluated\\ncross_error_max={}\\ncross_error_avg={}'.format(cross_error_max,\n",
    "                                                                                                 cross_error_avg))\n",
    "                spectral_error_max, spectral_error_avg = func_difference_metrics(F, W_spectral, max_length=max_length)\n",
    "                print(\n",
    "                    'errors has been evaluated\\nspectral_error_max={}\\nspectral_error_avg={}'.format(spectral_error_max,\n",
    "                                                                                                     spectral_error_avg))\n",
    "                random_spectral_error_max, random_spectral_error_avg = func_difference_metrics(F, W_spectral,\n",
    "                                                                                               max_length=max_length)\n",
    "                print('errors has been evaluated\\nrandom_spectral_error_max={}\\nrandom_spectral_error_avg={}'.format(\n",
    "                    random_spectral_error_max, random_spectral_error_avg))\n",
    "\n",
    "                df_result = df_result.append({'alphabet_size': alphabet_size,\n",
    "                                              'rank': rank,\n",
    "                                              'n': n,\n",
    "                                              'n_evaluations': n_evaluations,\n",
    "                                              'set_size': set_size,\n",
    "                                              'tensor_extraction_time': tensor_extraction_time,\n",
    "                                              'val_epss': info['val_epss'],\n",
    "                                              'cross_wfa_extraction_time': cross_wfa_extraction_time,\n",
    "                                              'hankel_creation_time[short]': hankel_creation_time,\n",
    "                                              'spectral_wfa_extraction_time[short]': spectral_wfa_extraction_time,\n",
    "                                              'hankel_creation_time[random]': random_hankel_creation_time,\n",
    "                                              'spectral_wfa_extraction_time[random]': random_spectral_wfa_extraction_time,\n",
    "                                              'error_max[cross]': cross_error_max,\n",
    "                                              'error_avg[cross]': cross_error_avg,\n",
    "                                              'error_max[short]': spectral_error_max,\n",
    "                                              'error_avg[short]': spectral_error_avg,\n",
    "                                              'error_max[random]': random_spectral_error_max,\n",
    "                                              'error_avg[random]': random_spectral_error_avg}, ignore_index=True)\n",
    "\n",
    "        df_result.to_csv('csv_{}_{}.csv'.format(filename, alphabet_size))\n",
    "\n",
    "    return df_result.astype({'alphabet_size': 'int64',\n",
    "                             'rank': 'int64',\n",
    "                             'n': 'int64',\n",
    "                             'n_evaluations': 'int64',\n",
    "                             'set_size': 'int64',\n",
    "                             'tensor_extraction_time': 'float64',\n",
    "                             'cross_wfa_extraction_time': 'float64',\n",
    "                             'hankel_creation_time[short]': 'float64',\n",
    "                             'spectral_wfa_extraction_time[short]': 'float64',\n",
    "                             'hankel_creation_time[random]': 'float64',\n",
    "                             'spectral_wfa_extraction_time[random]': 'float64'})"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyOrZkh368Ff"
   },
   "source": [
    "### 3. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BvcnnbUexSQi"
   },
   "source": [
    "from wfa_extraction import RandomNormalWFA\n",
    "\n",
    "\n",
    "def test_function(seq):\n",
    "    value = 0\n",
    "    for x in seq:\n",
    "        value = value + x ** 2\n",
    "    return (np.sin(value) ** 3) * 0.1\n",
    "\n",
    "\n",
    "class Sum:\n",
    "    def __init__(self, A, noise):\n",
    "        self.A = A\n",
    "        self.noise = noise\n",
    "        self.alphabet_size = A.alphabet_size\n",
    "\n",
    "    def f(self, seq):\n",
    "        return self.A.f(seq) + self.noise(seq)\n",
    "\n",
    "\n",
    "W1 = RandomNormalWFA(20, 10, lval=0.5, rval=1.5, seed=239)\n",
    "W = Sum(W1, test_function)\n",
    "\n",
    "df_result = experiment(W, filename='wfa-tensor', alphabet_size_list=[10, 15, 20], ranks_list=[10], n_list=[1, 2, 3, 4],\n",
    "                       max_length=10, max_iter=3)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u-Ewa2aDxadz"
   },
   "source": [
    "df_result.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_WVjKgy67CKF"
   },
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pdf = PdfPages('plots_avg1.pdf')\n",
    "crop_len = 10\n",
    "\n",
    "f, arr = plt.subplots(4, 3)\n",
    "f.set_figheight(16)\n",
    "f.set_figwidth(16)\n",
    "\n",
    "cnt = 0\n",
    "for index, row in df_result.iterrows():\n",
    "    idx = np.arange(crop_len + 1)\n",
    "    alphabet_size = row['alphabet_size']\n",
    "    rank = row['rank']\n",
    "    n = row['n']\n",
    "    x = n - 1\n",
    "    y = (alphabet_size // 5) - 2\n",
    "    arr[x][y].plot(idx, row['error_avg[short]'][:(crop_len + 1)], label='short')\n",
    "    arr[x][y].plot(idx, row['error_avg[cross]'][:(crop_len + 1)], label='cross')\n",
    "    arr[x][y].plot(idx, row['error_avg[random]'][:(crop_len + 1)], label='random')\n",
    "    arr[x][y].legend()\n",
    "    arr[x][y].title.set_text(\n",
    "        'alphabet_size={}, rank={}, k={} [{} evals]'.format(alphabet_size, rank, n, row['n_evaluations']))\n",
    "    if y == 0:\n",
    "        arr[x][y].set_ylabel('average error')\n",
    "    if x == 3:\n",
    "        arr[x][y].set_xlabel('length')\n",
    "    cnt += 1\n",
    "\n",
    "pdf.savefig(f)\n",
    "pdf.close()\n",
    "\n",
    "f.savefig('plots3.jpg', bbox_inches='tight', pad_inches=0.01)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VtY97F2y7ksC"
   },
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "pdf = PdfPages('plots_max1.pdf')\n",
    "crop_len = 10\n",
    "\n",
    "f, arr = plt.subplots(4, 3)\n",
    "f.set_figheight(16)\n",
    "f.set_figwidth(16)\n",
    "\n",
    "cnt = 0\n",
    "for index, row in df_result.iterrows():\n",
    "    idx = np.arange(crop_len + 1)\n",
    "    alphabet_size = row['alphabet_size']\n",
    "    rank = row['rank']\n",
    "    n = row['n']\n",
    "    x = n - 1\n",
    "    y = (alphabet_size // 5) - 2\n",
    "    arr[x][y].plot(idx, row['error_max[short]'][:(crop_len + 1)], label='short')\n",
    "    arr[x][y].plot(idx, row['error_max[cross]'][:(crop_len + 1)], label='cross')\n",
    "    arr[x][y].plot(idx, row['error_max[random]'][:(crop_len + 1)], label='random')\n",
    "    arr[x][y].legend()\n",
    "    arr[x][y].title.set_text(\n",
    "        'alphabet_size={}, rank={}, k={} [{} evals]'.format(alphabet_size, rank, n, row['n_evaluations']))\n",
    "    if y == 0:\n",
    "        arr[x][y].set_ylabel('maximum error')\n",
    "    if x == 3:\n",
    "        arr[x][y].set_xlabel('length')\n",
    "    cnt += 1\n",
    "\n",
    "pdf.savefig(f)\n",
    "pdf.close()\n",
    "\n",
    "f.savefig('plots4.jpg', bbox_inches='tight', pad_inches=0.01)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
